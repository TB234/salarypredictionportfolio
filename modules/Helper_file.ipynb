{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to do\n",
    "# explore what to do with duplicates\n",
    "# EDA on how a particular industry pays a particular major more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_file_csv(file_link):\n",
    "    pd.read_csv(file_link)\n",
    "    print(\" Displaying Snipet of Data\")\n",
    "    return  pd.read_csv(file_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_stat(data):\n",
    "    \n",
    "    print ('Shape of data is {} ' .format(data.shape), end ='\\n\\n')\n",
    "    print ('  Data type', data.dtypes, sep = '\\n')\n",
    "    return data.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class summary_stats():\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        print ('Shape of data is {} ' .format(data.shape), end ='\\n\\n')\n",
    "        print ('  Data type', data.dtypes, sep = '\\n')\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniq_values_in_feature(data, feature):\n",
    "#accept feature as string or list of strings and drop feature if all values in features are unique \n",
    "    print(\"\")\n",
    "    x =[]\n",
    "    if type(feature) == list:\n",
    "        for i in feature:\n",
    "            uniq_vals = data[i].unique()\n",
    "            l = len (uniq_vals)\n",
    "            print('There are %s  unique values of %s' %(l, i) )\n",
    "            #[print(val, end = ' ') for val in uniq_vals]\n",
    "            if data.shape[0] == l:\n",
    "               x.append(i)\n",
    "            else: \n",
    "                continue\n",
    "        return drop_feature(data, x)\n",
    "    else:\n",
    "        uniq_vals = data[feature].unique()\n",
    "        l = len (uniq_vals)\n",
    "        print('There are %s  unique values of %s' %(l, feature) )\n",
    "        #[print(val, end = ',') for val in uniq_vals]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_set_joiner(data_1, data_2, joiner, How):\n",
    "    return data_1.join(data_2.set_index(joiner), on = joiner, how = How )\n",
    "    #return pd.merge(data_1, data_2, on = 'jobId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_vals(data):\n",
    "    print('Percent missing of total')\n",
    "    return data.isnull().sum()/len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def case_check(data):\n",
    "    print('Checking if case in feature values are uniform')\n",
    "    counter = data.shape[0]\n",
    "    for i in data.columns:\n",
    "        if data[i].dtype == object:\n",
    "            total_uppercase = sum(data[i].apply(lambda x: x.isupper()))\n",
    "            if counter == total_uppercase:\n",
    "                print (i, '--->','OK')\n",
    "            else: \n",
    "                print (i, '--->', 'NOT OK')\n",
    "    print('')          \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_missing (data, target): #drop missing value and empty strings\n",
    "    print('Output After dropping missing values')\n",
    "    pd.options.mode.use_inf_as_na = True #sets empty strings as nan\n",
    "    data.dropna(inplace = True)\n",
    "    if target in data.columns:\n",
    "        return data[data[target] > 0]\n",
    "    else:\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dup(data):\n",
    "    duplicates = sum(data.duplicated() == True)\n",
    "    print('%d duplicates found' %duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_dup(data):\n",
    "    duplicates = sum(data.duplicated() == True)\n",
    "    print('%d duplicates found' %duplicates)\n",
    "    if duplicates > 0:\n",
    "        print('Output after dropping duplicates')\n",
    "        return data.drop_duplicates()\n",
    "    else:\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_feature(data, feature):\n",
    "    return data.drop( axis=1, columns = feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group(data, features, fillter = 0):\n",
    "    grouped_data = data.groupby(features).agg(list)\n",
    "    if fillter == 0:   \n",
    "        return grouped_data\n",
    "    else:   \n",
    "        return grouped_data[grouped_data['salary'].apply(lambda x: len(x)> fillter)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inpt_feat():\n",
    "    feat_list = []\n",
    "    t = True\n",
    "    while t:\n",
    "        feat_list.append(str(input('add your feature: ')))\n",
    "        f= str(input('Done?(y/n): '))\n",
    "        if f == 'y':\n",
    "            t = False\n",
    "        else:\n",
    "            t= True\n",
    "    return feat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show duplicated data on features set with corresponding target\n",
    "\n",
    "def dup_feat(data, target_col):\n",
    "    print ('Number of duplicates found ---> ', sum(data.drop(columns = target_col).duplicated()== True))\n",
    "    return data[data.drop(columns = target_col).duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drops duplicates after excluding columns and merges back. will remove corresponding row in dropped columns\n",
    "#target columns in string or list of strings\n",
    "def drop_dup1(data, target_col = None ):    \n",
    "    if target_col == None:\n",
    "        print ('Number of duplicates found ---> ', sum(data.duplicated() == True))\n",
    "        return data.drop_duplicates()\n",
    "    else:\n",
    "        print ('Number of duplicates found ---> ', sum(data.drop(columns = target_col).duplicated()== True)) \n",
    "        return data[data.drop(columns = target_col).duplicated()== False] \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choosing mean median mode of target for duplicated features\n",
    "# types in string\n",
    "def select_clean_met(data, feature_list, types):\n",
    "    if types == 'mean':\n",
    "         return data.groupby(feature_list).mean().reset_index()\n",
    "    elif types == 'max':\n",
    "        return data.groupby(feature_list).max().reset_index()\n",
    "    elif types == 'min':\n",
    "        return data.groupby(feature_list).min().reset_index()\n",
    "    elif types== 'median':\n",
    "        return data.groupby(feature_list).median().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_binned_feat(data, feature, num_bins, bin_labels, new_feat_name):\n",
    "    data[new_feat_name] = pd.cut(data[feature], num_bins, labels = bin_labels )\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_list should be a string or list of strings\n",
    "def drop_feats(data, feature_list):\n",
    "    data.drop(columns = feature_list, inplace = True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_feat_type(data, feature, to_type ):\n",
    "    for i in feature:\n",
    "        data[i] = data[i].astype(to_type)\n",
    "        print(i, 'data type --->',  data[i].dtype)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to import shuffle from sklearn.utils\n",
    "def div_train_test(data, train_frac, seed):\n",
    "    data = shuffle(data, random_state = seed)\n",
    "    sample_train = data.sample(frac = train_frac, random_state = seed)\n",
    "    sample_test = data.drop(sample_train.index)\n",
    "    print ('data splitted into sample_train and sample_test')\n",
    "    return sample_train, sample_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregates targets after grouping to create new features\n",
    "def new_tar_feat(data, target):\n",
    "    data['group_mean']= data[target].apply(lambda x: np.mean(x))\n",
    "    data['group_max']= data[target].apply(lambda x: np.max(x))\n",
    "    data['group_min']= data[target].apply(lambda x: np.min(x))\n",
    "    data['group_std']= data[target].apply(lambda x: np.std(x))\n",
    "    data['group_median']= data[target].apply(lambda x: np.median(x))\n",
    "    data['group_range']= data[target].apply(lambda x: np.ptp(x))\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merger function\n",
    "def merger(base_data, merger_data, merg_on_feat, how= None):\n",
    "    return base_data.merge(merger_data, on = merg_on_feat, how = how )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a pivot table and color map\n",
    "def color_map(pivot_row, pivot_column):\n",
    "    group = sample_train[[pivot_row, pivot_column, 'salary']]\n",
    "    group = group.groupby([pivot_row, pivot_column], as_index = False).mean()\n",
    "\n",
    "    pivot_table = group.pivot(index = pivot_row, columns = pivot_column)\n",
    "\n",
    "    fig1, ax = plt.subplots( figsize= (10,10))\n",
    "\n",
    "    clr_map = ax.pcolormesh(pivot_table, cmap='RdBu')\n",
    "\n",
    "    ax.set_xticks(np.arange(pivot_table.shape[1])+ 0.5)\n",
    "    ax.set_yticks(np.arange(pivot_table.shape[0])+ 0.5)\n",
    "\n",
    "    ax.set_xticklabels(pivot_table.columns.levels[1])\n",
    "    ax.set_yticklabels(pivot_table.index)\n",
    "\n",
    "    plt.xticks(rotation=90)\n",
    "\n",
    "\n",
    "    fig1.colorbar(clr_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create pivot table\n",
    "def pivot_table(data, pivot_row, pivot_column, target):\n",
    "    group = data[[pivot_row, pivot_column, target]].groupby([pivot_row, pivot_column], as_index = False).mean()\n",
    "    return group.pivot(index = pivot_row, columns = pivot_column).sort_values( data[pivot_row].unique()[0], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot line graphs of feature against salary with an additional feature dimension as filter \n",
    "def plot_feature_corr(data, feature1, feature2, target):\n",
    "    grouped_data = data[[feature1, feature2, target]].groupby([feature1, feature2], as_index = True).mean()\n",
    "    grouped_data.reset_index(level = feature2, inplace = True)\n",
    "\n",
    "  \n",
    "    fig = plt.figure(figsize = (10,10))\n",
    "    ax = fig.add_axes([0,0,1,1])\n",
    "    \n",
    "    counter = 0\n",
    "    for i in data[feature1].unique():\n",
    "       \n",
    "        ax.plot(grouped_data.loc[i].sort_values(target)[feature2], grouped_data.loc[i].sort_values(target)[target], \n",
    "                color = 'C'+ str(counter), marker = 's', label=i )\n",
    "        counter += 1\n",
    "   \n",
    "    ax.set_ylabel('Average Salary ')\n",
    "    ax.set_xlabel(feature2)\n",
    "    ax.legend(  loc = 'lower right',  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot a categorical feature value against target \n",
    "def feat_val_graph(data, pivot_row, pivot_column, target, row_feat_val):\n",
    "    table = pivot_table(data, pivot_row, pivot_column, target).loc[row_feat_val].reset_index()\n",
    "    table.drop('level_0', axis = 1, inplace = True)\n",
    "    table. rename(columns = {row_feat_val: target.upper()}, inplace = True)\n",
    "    plt.figure(figsize = (5,5))\n",
    "    plt.plot(table[pivot_column], table[target.upper()] )\n",
    "    plt.title(label = row_feat_val +' ' + pivot_row.upper() )\n",
    "    plt.ylabel( ylabel = 'Average' + ' ' + target.upper())\n",
    "    plt.xlabel( xlabel = pivot_column.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot bar graphs of features\n",
    "def feat_dist(data, feat_list):\n",
    "    fig, ax = plt.subplots(len(feat_list),1, figsize = (20,20))\n",
    "    cnt = 0\n",
    "    for i in feat_list:\n",
    "        ax[cnt].bar(data[i].sort_values().unique(), data[i].value_counts().sort_index())\n",
    "        cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot box plots\n",
    "def feat_boxplot(data, feature, target):\n",
    "    fig = plt.figure( figsize=(10,10))\n",
    "    axs = fig.add_axes([0,0,1,1])\n",
    "    sns.boxplot(x = feature, y = target, data =data, ax = axs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label encoder function\n",
    "#feature and enc_feat_name can be strings or list of strings \n",
    "def lab_enc(data, feature, enc_feat_nam):\n",
    "    le = LabelEncoder()\n",
    "    if type(feature) == list:\n",
    "        cnt = 0  \n",
    "        for i in feature:\n",
    "            data[enc_feat_nam[cnt]] = le.fit_transform(data[i])\n",
    "            cnt += 1\n",
    "    elif type(feature) == str:\n",
    "        data[enc_feat_nam] = le.fit_transform(data[feature])\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ordinal encoder function\n",
    "#category_order_list could be a single list or list of multiple lists\n",
    "#feature, enc_feat_nam could be string or list of strings\n",
    "def ord_enc(data, feature, cat_ord_lst, enc_feat_nam):\n",
    "    ord_encoder = OrdinalEncoder(categories = cat_ord_lst, dtype= 'int64')\n",
    "    if type(feature)== str:\n",
    "        data[enc_feat_nam]= ord_encoder.fit_transform(data[[feature]])\n",
    "    elif type(feature) == list:\n",
    "        data.reset_index(inplace = True)\n",
    "        data.drop(axis = 1, columns= 'index', inplace = True )\n",
    "        data[enc_feat_nam] = pd.DataFrame(ord_encoder.fit_transform(data[feature]))\n",
    "       \n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that assign numbers to the unique feature values and stores in dictionary \n",
    "def num_assign(data, feature):\n",
    "    map_val = {}\n",
    "    unique_val = data[feature].unique()\n",
    "    \n",
    "    for i in range(len(unique_val)):\n",
    "        map_val[unique_val[i]] = i\n",
    "    return map_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alternative to sklearn label or ordinal encoder\n",
    "def map_encod(data, feat, lis, enc_feat_nam):\n",
    "    if type(feat) == str:\n",
    "        data[enc_feat_nam] = data[feat].map(lis)\n",
    "    elif type(feat) == list:\n",
    "        for i in range(len(feat)):\n",
    "            data[enc_feat_nam[i]]= data[feat[i]].map(lis[i])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_enc(data, feat):\n",
    "    return pd.get_dummies(data, columns = feat, drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function creates list of numerical features in dataframe\n",
    "def num_feat_list(data, target):\n",
    "    c= []\n",
    "    for feature in data.columns:\n",
    "        if data[feature].dtype != object and feature != target :\n",
    "            c.append(feature)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If user provides a separate test sample it used, otherwise a portion of train sample is reserved for testing\n",
    "def use_data(train_sample, test_sample = 'auto', num_features = 'auto'):\n",
    "    \n",
    "    #gets all numerical features from data if auto is used\n",
    "    if num_features == 'auto':\n",
    "                num_features = num_feat_list(train_sample, target)\n",
    "    \n",
    "    #Check\n",
    "    if type(test_sample) == str:\n",
    "        x = train_sample[ num_features ]\n",
    "        y = train_sample [target]\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state = 1)\n",
    "\n",
    "    else:\n",
    "        x_train = train_sample[ num_features ]\n",
    "        y_train = train_sample [target]\n",
    "        x_test = test_sample[num_features]\n",
    "        y_test = test_sample[target]\n",
    "        \n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def best_model_mse(train_sample,  target,  num_features = 'auto', test_sample = 'auto'):\n",
    "    \n",
    "    #gets all numerical features from data if auto is used\n",
    "    if num_features == 'auto':\n",
    "                num_features = num_feat_list(train_sample, target)\n",
    "            \n",
    "    x_train, y_train, x_test, y_test = use_data(train_sample, test_sample, num_features)\n",
    "\n",
    "#models\n",
    "    dt = tree.DecisionTreeRegressor(max_depth= 30, max_features = 'auto', \n",
    "                                        min_samples_split=130, random_state = 1, ccp_alpha = 0.0001 )\n",
    "\n",
    "    rf = RandomForestRegressor(n_estimators = 100, min_samples_split = 20, min_samples_leaf = 8, verbose = 0,\n",
    "                               max_features = 'sqrt', max_samples= 100000, random_state = 1, oob_score= True, n_jobs = -1, bootstrap = True )\n",
    "\n",
    "    grad_bst = GradientBoostingRegressor(n_estimators = 100, max_depth= 9, max_features = 5, learning_rate = 0.1, \n",
    "                                   min_samples_split = 8, min_samples_leaf = 8, verbose = 0, random_state = 3)\n",
    "\n",
    "\n",
    "    xg_bst = xgboost.XGBRegressor(n_jobs = -1, random_state = 2, n_estimators = 100, max_depth = 8, min_child_weight= 8, \n",
    "                               reg_lambda = 1, reg_alpha = 20, learning_rate = 0.09, base_score= 0.5, colsample_bytree = 0.8, subsample = 1)\n",
    "\n",
    "\n",
    "    models = {dt : 'Dec_tree', rf: 'rand_forest', grad_bst : 'gradient_boost', xg_bst : 'xtreme_grad_boost'}\n",
    "    #models = {dt : 'Dec_tree', rf: 'rand_forest'}\n",
    "\n",
    "    #print ('CROSS VAL MSE SCORES')\n",
    "\n",
    "    #for keys in models.keys():\n",
    "    #    cross = cross_validate(keys, x_train, y_train, n_jobs= -1, scoring = ('neg_mean_squared_error'),\n",
    "    #                           cv=5, return_train_score=True, return_estimator= False, verbose = 0)\n",
    "    #   print(models[keys], '----> ', cross['test_score'])\n",
    "\n",
    "    model_mse = {}\n",
    "    for keys in models.keys():\n",
    "        keys.fit(x_train, y_train)\n",
    "\n",
    "        yhat_test = keys.predict(x_test)\n",
    "\n",
    "        mse = mean_squared_error(yhat_test, y_test)\n",
    "        model_mse[models[keys]] = mse\n",
    "\n",
    "    print('MODEL MSEs')\n",
    "    for key,value in model_mse.items():\n",
    "        print(key, '--->', value)\n",
    "        \n",
    "    best_mod = min(model_mse.keys(), key=(lambda k: model_mse[k]))\n",
    "    \n",
    "    for key, value in models.items():\n",
    "        if value == best_mod:\n",
    "            joblib.dump(key, 'saved_best_model')\n",
    "            \n",
    "            print ('\\n', 'Best model ----> ', value)\n",
    "            \n",
    "            print('\\n', 'FEATURE IMPORTANCE')\n",
    "            for i in range(len(num_features)):\n",
    "                print( num_features[i] , '-----> ', key.feature_importances_[i])\n",
    "            \n",
    "            return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'z'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict = {'x': 4, 'y':2, 'z':1}\n",
    "\n",
    "max(dict.keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Value:  560\n",
      "Minimum Value:  500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'z'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dict = {'x':500, 'y':5874, 'z': 560}\n",
    "\n",
    "key_max = max(my_dict.keys(), key=(lambda k: my_dict[k]))\n",
    "key_min = min(my_dict.keys(), key=(lambda k: my_dict[k]))\n",
    "\n",
    "print('Maximum Value: ',my_dict[key_max])\n",
    "print('Minimum Value: ',my_dict[key_min])\n",
    "key_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "X, y = make_classification(n_samples=100, random_state=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,\n",
    "                                                    random_state=1)\n",
    " Reg = MLPRegressor(random_state=1, max_iter=300).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_df[\"OHC_Code\"] = np.where(obj_df[\"engine_type\"].str.contains(\"ohc\"), 1, other=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " FEATURE IMPORTANCE\n",
    "yearsExperience ----->  0.08069982\n",
    "milesFromMetropolis ----->  0.0817066\n",
    "yearsExperience_group ----->  0.17233479\n",
    "mfm_group ----->  0.025737463\n",
    "enc_ind ----->  0.11017496\n",
    "enc_deg ----->  0.118915424\n",
    "enc_maj ----->  0.04385577\n",
    "enc_jobtype ----->  0.36657515\n",
    "\n",
    " The train mean squared error 326.98478830633087\n",
    "The test mean squared error  359.6487194303258\n",
    "\n",
    "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "             colsample_bynode=1, colsample_bytree=0.8, gamma=0, gpu_id=-1,\n",
    "             importance_type='gain', interaction_constraints='',\n",
    "             learning_rate=0.09, max_delta_step=0, max_depth=8,\n",
    "             min_child_weight=8, missing=nan, monotone_constraints='()',\n",
    "             n_estimators=1000, n_jobs=-1, num_parallel_tree=1, random_state=2,\n",
    "             reg_alpha=20, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
    "             tree_method='exact', validate_parameters=1, verbosity=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
